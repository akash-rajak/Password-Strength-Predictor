{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PASSWORD STRENGTH PREDICTING NLP/ML MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  first we need to read the data from data.csv file, therefore we need to import the basic python library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns # we can also use matplotlib for visulaization purpose\n",
    "import warnings  # to get rid of all the warnings that come across the cell, we import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### READING THE DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 2810: expected 2 fields, saw 5\\nSkipping line 4641: expected 2 fields, saw 5\\nSkipping line 7171: expected 2 fields, saw 5\\nSkipping line 11220: expected 2 fields, saw 5\\nSkipping line 13809: expected 2 fields, saw 5\\nSkipping line 14132: expected 2 fields, saw 5\\nSkipping line 14293: expected 2 fields, saw 5\\nSkipping line 14865: expected 2 fields, saw 5\\nSkipping line 17419: expected 2 fields, saw 5\\nSkipping line 22801: expected 2 fields, saw 5\\nSkipping line 25001: expected 2 fields, saw 5\\nSkipping line 26603: expected 2 fields, saw 5\\nSkipping line 26742: expected 2 fields, saw 5\\nSkipping line 29702: expected 2 fields, saw 5\\nSkipping line 32767: expected 2 fields, saw 5\\nSkipping line 32878: expected 2 fields, saw 5\\nSkipping line 35643: expected 2 fields, saw 5\\nSkipping line 36550: expected 2 fields, saw 5\\nSkipping line 38732: expected 2 fields, saw 5\\nSkipping line 40567: expected 2 fields, saw 5\\nSkipping line 40576: expected 2 fields, saw 5\\nSkipping line 41864: expected 2 fields, saw 5\\nSkipping line 46861: expected 2 fields, saw 5\\nSkipping line 47939: expected 2 fields, saw 5\\nSkipping line 48628: expected 2 fields, saw 5\\nSkipping line 48908: expected 2 fields, saw 5\\nSkipping line 57582: expected 2 fields, saw 5\\nSkipping line 58782: expected 2 fields, saw 5\\nSkipping line 58984: expected 2 fields, saw 5\\nSkipping line 61518: expected 2 fields, saw 5\\nSkipping line 63451: expected 2 fields, saw 5\\nSkipping line 68141: expected 2 fields, saw 5\\nSkipping line 72083: expected 2 fields, saw 5\\nSkipping line 74027: expected 2 fields, saw 5\\nSkipping line 77811: expected 2 fields, saw 5\\nSkipping line 83958: expected 2 fields, saw 5\\nSkipping line 85295: expected 2 fields, saw 5\\nSkipping line 88665: expected 2 fields, saw 5\\nSkipping line 89198: expected 2 fields, saw 5\\nSkipping line 92499: expected 2 fields, saw 5\\nSkipping line 92751: expected 2 fields, saw 5\\nSkipping line 93689: expected 2 fields, saw 5\\nSkipping line 94776: expected 2 fields, saw 5\\nSkipping line 97334: expected 2 fields, saw 5\\nSkipping line 102316: expected 2 fields, saw 5\\nSkipping line 103421: expected 2 fields, saw 5\\nSkipping line 106872: expected 2 fields, saw 5\\nSkipping line 109363: expected 2 fields, saw 5\\nSkipping line 110117: expected 2 fields, saw 5\\nSkipping line 110465: expected 2 fields, saw 5\\nSkipping line 113843: expected 2 fields, saw 5\\nSkipping line 115634: expected 2 fields, saw 5\\nSkipping line 121518: expected 2 fields, saw 5\\nSkipping line 123692: expected 2 fields, saw 5\\nSkipping line 124708: expected 2 fields, saw 5\\nSkipping line 129608: expected 2 fields, saw 5\\nSkipping line 133176: expected 2 fields, saw 5\\nSkipping line 135532: expected 2 fields, saw 5\\nSkipping line 138042: expected 2 fields, saw 5\\nSkipping line 139485: expected 2 fields, saw 5\\nSkipping line 140401: expected 2 fields, saw 5\\nSkipping line 144093: expected 2 fields, saw 5\\nSkipping line 149850: expected 2 fields, saw 5\\nSkipping line 151831: expected 2 fields, saw 5\\nSkipping line 158014: expected 2 fields, saw 5\\nSkipping line 162047: expected 2 fields, saw 5\\nSkipping line 164515: expected 2 fields, saw 5\\nSkipping line 170313: expected 2 fields, saw 5\\nSkipping line 171325: expected 2 fields, saw 5\\nSkipping line 171424: expected 2 fields, saw 5\\nSkipping line 175920: expected 2 fields, saw 5\\nSkipping line 176210: expected 2 fields, saw 5\\nSkipping line 183603: expected 2 fields, saw 5\\nSkipping line 190264: expected 2 fields, saw 5\\nSkipping line 191683: expected 2 fields, saw 5\\nSkipping line 191988: expected 2 fields, saw 5\\nSkipping line 195450: expected 2 fields, saw 5\\nSkipping line 195754: expected 2 fields, saw 5\\nSkipping line 197124: expected 2 fields, saw 5\\nSkipping line 199263: expected 2 fields, saw 5\\nSkipping line 202603: expected 2 fields, saw 5\\nSkipping line 209960: expected 2 fields, saw 5\\nSkipping line 213218: expected 2 fields, saw 5\\nSkipping line 217060: expected 2 fields, saw 5\\nSkipping line 220121: expected 2 fields, saw 5\\nSkipping line 223518: expected 2 fields, saw 5\\nSkipping line 226293: expected 2 fields, saw 5\\nSkipping line 227035: expected 2 fields, saw 7\\nSkipping line 227341: expected 2 fields, saw 5\\nSkipping line 227808: expected 2 fields, saw 5\\nSkipping line 228516: expected 2 fields, saw 5\\nSkipping line 228733: expected 2 fields, saw 5\\nSkipping line 232043: expected 2 fields, saw 5\\nSkipping line 232426: expected 2 fields, saw 5\\nSkipping line 234490: expected 2 fields, saw 5\\nSkipping line 239626: expected 2 fields, saw 5\\nSkipping line 240461: expected 2 fields, saw 5\\nSkipping line 244518: expected 2 fields, saw 5\\nSkipping line 245395: expected 2 fields, saw 5\\nSkipping line 246168: expected 2 fields, saw 5\\nSkipping line 246655: expected 2 fields, saw 5\\nSkipping line 246752: expected 2 fields, saw 5\\nSkipping line 247189: expected 2 fields, saw 5\\nSkipping line 250276: expected 2 fields, saw 5\\nSkipping line 255327: expected 2 fields, saw 5\\nSkipping line 257094: expected 2 fields, saw 5\\n'\n",
      "b'Skipping line 264626: expected 2 fields, saw 5\\nSkipping line 265028: expected 2 fields, saw 5\\nSkipping line 269150: expected 2 fields, saw 5\\nSkipping line 271360: expected 2 fields, saw 5\\nSkipping line 273975: expected 2 fields, saw 5\\nSkipping line 274742: expected 2 fields, saw 5\\nSkipping line 276227: expected 2 fields, saw 5\\nSkipping line 279807: expected 2 fields, saw 5\\nSkipping line 283425: expected 2 fields, saw 5\\nSkipping line 287468: expected 2 fields, saw 5\\nSkipping line 292995: expected 2 fields, saw 5\\nSkipping line 293496: expected 2 fields, saw 5\\nSkipping line 293735: expected 2 fields, saw 5\\nSkipping line 295060: expected 2 fields, saw 5\\nSkipping line 296643: expected 2 fields, saw 5\\nSkipping line 296848: expected 2 fields, saw 5\\nSkipping line 308926: expected 2 fields, saw 5\\nSkipping line 310360: expected 2 fields, saw 5\\nSkipping line 317004: expected 2 fields, saw 5\\nSkipping line 318207: expected 2 fields, saw 5\\nSkipping line 331783: expected 2 fields, saw 5\\nSkipping line 333864: expected 2 fields, saw 5\\nSkipping line 335958: expected 2 fields, saw 5\\nSkipping line 336290: expected 2 fields, saw 5\\nSkipping line 343526: expected 2 fields, saw 5\\nSkipping line 343857: expected 2 fields, saw 5\\nSkipping line 344059: expected 2 fields, saw 5\\nSkipping line 348691: expected 2 fields, saw 5\\nSkipping line 353446: expected 2 fields, saw 5\\nSkipping line 357073: expected 2 fields, saw 5\\nSkipping line 359753: expected 2 fields, saw 5\\nSkipping line 359974: expected 2 fields, saw 5\\nSkipping line 366534: expected 2 fields, saw 5\\nSkipping line 369514: expected 2 fields, saw 5\\nSkipping line 377759: expected 2 fields, saw 5\\nSkipping line 379327: expected 2 fields, saw 5\\nSkipping line 380769: expected 2 fields, saw 5\\nSkipping line 381073: expected 2 fields, saw 5\\nSkipping line 381489: expected 2 fields, saw 5\\nSkipping line 386304: expected 2 fields, saw 5\\nSkipping line 387635: expected 2 fields, saw 5\\nSkipping line 389613: expected 2 fields, saw 5\\nSkipping line 392604: expected 2 fields, saw 5\\nSkipping line 393184: expected 2 fields, saw 5\\nSkipping line 395530: expected 2 fields, saw 5\\nSkipping line 396939: expected 2 fields, saw 5\\nSkipping line 397385: expected 2 fields, saw 5\\nSkipping line 397509: expected 2 fields, saw 5\\nSkipping line 402902: expected 2 fields, saw 5\\nSkipping line 405187: expected 2 fields, saw 5\\nSkipping line 408412: expected 2 fields, saw 5\\nSkipping line 419423: expected 2 fields, saw 5\\nSkipping line 420962: expected 2 fields, saw 5\\nSkipping line 425965: expected 2 fields, saw 5\\nSkipping line 427496: expected 2 fields, saw 5\\nSkipping line 438881: expected 2 fields, saw 5\\nSkipping line 439776: expected 2 fields, saw 5\\nSkipping line 440345: expected 2 fields, saw 5\\nSkipping line 445507: expected 2 fields, saw 5\\nSkipping line 445548: expected 2 fields, saw 5\\nSkipping line 447184: expected 2 fields, saw 5\\nSkipping line 448603: expected 2 fields, saw 5\\nSkipping line 451732: expected 2 fields, saw 5\\nSkipping line 458249: expected 2 fields, saw 5\\nSkipping line 460274: expected 2 fields, saw 5\\nSkipping line 467630: expected 2 fields, saw 5\\nSkipping line 473961: expected 2 fields, saw 5\\nSkipping line 476281: expected 2 fields, saw 5\\nSkipping line 478010: expected 2 fields, saw 5\\nSkipping line 478322: expected 2 fields, saw 5\\nSkipping line 479999: expected 2 fields, saw 5\\nSkipping line 480898: expected 2 fields, saw 5\\nSkipping line 481688: expected 2 fields, saw 5\\nSkipping line 485193: expected 2 fields, saw 5\\nSkipping line 485519: expected 2 fields, saw 5\\nSkipping line 486000: expected 2 fields, saw 5\\nSkipping line 489063: expected 2 fields, saw 5\\nSkipping line 494525: expected 2 fields, saw 5\\nSkipping line 495009: expected 2 fields, saw 5\\nSkipping line 501954: expected 2 fields, saw 5\\nSkipping line 508035: expected 2 fields, saw 5\\nSkipping line 508828: expected 2 fields, saw 5\\nSkipping line 509833: expected 2 fields, saw 5\\nSkipping line 510410: expected 2 fields, saw 5\\nSkipping line 518229: expected 2 fields, saw 5\\nSkipping line 520302: expected 2 fields, saw 5\\nSkipping line 520340: expected 2 fields, saw 5\\n'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 525174: expected 2 fields, saw 5\\nSkipping line 526251: expected 2 fields, saw 5\\nSkipping line 529611: expected 2 fields, saw 5\\nSkipping line 531398: expected 2 fields, saw 5\\nSkipping line 534146: expected 2 fields, saw 5\\nSkipping line 544954: expected 2 fields, saw 5\\nSkipping line 553002: expected 2 fields, saw 5\\nSkipping line 553883: expected 2 fields, saw 5\\nSkipping line 553887: expected 2 fields, saw 5\\nSkipping line 553915: expected 2 fields, saw 5\\nSkipping line 554172: expected 2 fields, saw 5\\nSkipping line 563534: expected 2 fields, saw 5\\nSkipping line 565191: expected 2 fields, saw 5\\nSkipping line 574108: expected 2 fields, saw 5\\nSkipping line 574412: expected 2 fields, saw 5\\nSkipping line 575985: expected 2 fields, saw 5\\nSkipping line 580091: expected 2 fields, saw 5\\nSkipping line 582682: expected 2 fields, saw 5\\nSkipping line 585885: expected 2 fields, saw 5\\nSkipping line 590171: expected 2 fields, saw 5\\nSkipping line 591924: expected 2 fields, saw 5\\nSkipping line 592515: expected 2 fields, saw 5\\nSkipping line 593888: expected 2 fields, saw 5\\nSkipping line 596245: expected 2 fields, saw 5\\nSkipping line 607344: expected 2 fields, saw 5\\nSkipping line 607633: expected 2 fields, saw 5\\nSkipping line 610939: expected 2 fields, saw 5\\nSkipping line 613638: expected 2 fields, saw 5\\nSkipping line 615643: expected 2 fields, saw 5\\nSkipping line 615901: expected 2 fields, saw 5\\nSkipping line 617389: expected 2 fields, saw 5\\nSkipping line 634641: expected 2 fields, saw 5\\nSkipping line 635755: expected 2 fields, saw 5\\nSkipping line 646243: expected 2 fields, saw 5\\nSkipping line 647165: expected 2 fields, saw 5\\nSkipping line 648610: expected 2 fields, saw 5\\nSkipping line 648772: expected 2 fields, saw 5\\nSkipping line 651833: expected 2 fields, saw 5\\nSkipping line 653663: expected 2 fields, saw 5\\nSkipping line 656233: expected 2 fields, saw 5\\nSkipping line 656694: expected 2 fields, saw 5\\nSkipping line 659783: expected 2 fields, saw 5\\nSkipping line 660478: expected 2 fields, saw 5\\nSkipping line 661133: expected 2 fields, saw 5\\nSkipping line 661736: expected 2 fields, saw 5\\nSkipping line 669827: expected 2 fields, saw 5\\n'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>password</th>\n",
       "      <th>strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kzde5577</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kino3434</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>visi7k1yr</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>megzy123</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lamborghin1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      password  strength\n",
       "0     kzde5577         1\n",
       "1     kino3434         1\n",
       "2    visi7k1yr         1\n",
       "3     megzy123         1\n",
       "4  lamborghin1         1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('data.csv',error_bad_lines=False)# read the data using read_csv function and setting the value of error_bad_lines = false, because it is by default true\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['strength'].unique() #Checking the unique strength present in dataset, 0-poor, 1 for average, 2 for best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHECKING ALL THE MISSING VALUES IN DATASET AND DROPPOING THEM ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "password    1\n",
       "strength    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum() # checking is there any Nan value in data, here only one value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>password</th>\n",
       "      <th>strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>367579</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       password  strength\n",
       "367579      NaN         0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['password'].isnull()] # finding the position where it is Nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True) # dropping that data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "password    0\n",
       "strength    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum() # after dropping , checking if there is not any Nan value, here 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='strength', ylabel='count'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data['strength']) # checking the freq of each category of strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "password_tuple=np.array(data) # now we create an array containing all the data of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['kzde5577', 1],\n",
       "       ['kino3434', 1],\n",
       "       ['visi7k1yr', 1],\n",
       "       ...,\n",
       "       ['184520socram', 1],\n",
       "       ['marken22a', 1],\n",
       "       ['fxx4pw4g', 1]], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "password_tuple # printing that array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['kzde5577', 1],\n",
       "       ['kino3434', 1],\n",
       "       ['kino3434', 1],\n",
       "       ...,\n",
       "       ['golubova-inga0W', 2],\n",
       "       ['KELOMPOK1117', 1],\n",
       "       ['magistakd7', 1]], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffling the data to create the robustness\n",
    "import random # therefore importing random\n",
    "random.shuffle(password_tuple) # using shuffle function make the array shuffled\n",
    "password_tuple # printing the array after shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for list comprehension\n",
    "# first column is put in x list\n",
    "# ans 2nd column in y list\n",
    "x=[labels[0] for labels in password_tuple]\n",
    "y=[labels[1] for labels in password_tuple]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kzde5577',\n",
       " 'kino3434',\n",
       " 'kino3434',\n",
       " 'megzy123',\n",
       " 'lamborghin1',\n",
       " 'visi7k1yr',\n",
       " 'AVYq1lDE4MgAZfNt',\n",
       " 'kino3434',\n",
       " 'lamborghin1',\n",
       " 'as326159',\n",
       " 'u6c8vhow',\n",
       " '612035180tok',\n",
       " 'universe2908',\n",
       " 'kino3434',\n",
       " 'asv5o9yu',\n",
       " 'megzy123',\n",
       " 'AVYq1lDE4MgAZfNt',\n",
       " 'visi7k1yr',\n",
       " 'AVYq1lDE4MgAZfNt',\n",
       " '612035180tok',\n",
       " 'kzde5577',\n",
       " '52558000aaa',\n",
       " 'kino3434',\n",
       " 'intel1',\n",
       " 'g067057895',\n",
       " 'lamborghin1',\n",
       " 'AVYq1lDE4MgAZfNt',\n",
       " 'as326159',\n",
       " 'czuodhj972',\n",
       " 'klara-tershina3H',\n",
       " 'jytifok873',\n",
       " 'cigicigi123',\n",
       " 'prisonbreak1',\n",
       " 'jytifok873',\n",
       " 'lamborghin1',\n",
       " 'cigicigi123',\n",
       " '0169395484a',\n",
       " '0169395484a',\n",
       " 'universe2908',\n",
       " 'czuodhj972',\n",
       " 'kswa2mrv',\n",
       " 'jytifok873',\n",
       " 'kino3434',\n",
       " 'gaymaids1',\n",
       " 'AVYq1lDE4MgAZfNt',\n",
       " 'pHyqueDIyNQ8vmhb',\n",
       " 'pHyqueDIyNQ8vmhb',\n",
       " 'sbl571017',\n",
       " 'fk9qi21m',\n",
       " 'elyass15@ajilent-ci',\n",
       " 'go7kew7a2po',\n",
       " 'yitbos77',\n",
       " 'trabajonet9',\n",
       " 'fahad123',\n",
       " 'AVYq1lDE4MgAZfNt',\n",
       " 'go7kew7a2po',\n",
       " 'kswa2mrv',\n",
       " 'kswa2mrv',\n",
       " 'alimagik1',\n",
       " 'prisonbreak1',\n",
       " 'yitbos77',\n",
       " 'go7kew7a2po',\n",
       " 'yitbos77',\n",
       " 'd04m11',\n",
       " '0169395484a',\n",
       " 'openup12',\n",
       " 'alimagik1',\n",
       " 'kino3434',\n",
       " 'kswa2mrv',\n",
       " 'b4NbTxDEyNgG141J',\n",
       " 'kzde5577',\n",
       " 'fk9qi21m',\n",
       " 'yk530mg8',\n",
       " 'kjkjkj1',\n",
       " 'universe2908',\n",
       " 'intel1',\n",
       " 'czuodhj972',\n",
       " 'kino3434',\n",
       " 'bozoxik602',\n",
       " 'c3h8bkzr',\n",
       " 'memjan123',\n",
       " 'schalke04',\n",
       " 'fk9qi21m',\n",
       " 'u6c8vhow',\n",
       " '52558000aaa',\n",
       " 'klara-tershina3H',\n",
       " 'hodygid757',\n",
       " 'ga98SIzk0NwhiZaE',\n",
       " 'WUt9IZzE0OQ7PkNE',\n",
       " 'universe2908',\n",
       " 'p2share',\n",
       " '52558000aaa',\n",
       " '0169395484a',\n",
       " 'yitbos77',\n",
       " 'calcifer32',\n",
       " 'yqugu927',\n",
       " 'yitbos77',\n",
       " 'alimagik1',\n",
       " '612035180tok',\n",
       " 'cigicigi123',\n",
       " 'g067057895',\n",
       " 'asv5o9yu',\n",
       " 'ns2b0727',\n",
       " 'patri1973',\n",
       " 'k9b8cz6aj2',\n",
       " 'k1k2k3k4k5k6',\n",
       " 'juliel009',\n",
       " 'kVczcljg4OA25Aeb',\n",
       " 'ejeko677',\n",
       " 'jalal123456',\n",
       " '12345yolanda',\n",
       " 'c3h8bkzr',\n",
       " 'hpqkoxsn5',\n",
       " 'kino3434',\n",
       " '612035180tok',\n",
       " 'bgrvl80',\n",
       " '283671gus',\n",
       " 'g067057895',\n",
       " 'khmer100.03278&?><Mnb',\n",
       " 'yu4cmn',\n",
       " 'intel1',\n",
       " 'kVczcljg4OA25Aeb',\n",
       " 'znbl5tj1',\n",
       " 'jytifok873',\n",
       " 'ns2b0727',\n",
       " 'k1k2k3k4k5k6',\n",
       " 'j09000',\n",
       " '746xitEGiqObog',\n",
       " 'pikey231',\n",
       " 'moken7',\n",
       " 'il0vey0u',\n",
       " 'zoobike04',\n",
       " 'klara-tershina3H',\n",
       " 'ass359',\n",
       " 'v1118714',\n",
       " 'b4NbTxDEyNgG141J',\n",
       " 'mickael12',\n",
       " 'gkrqjs6',\n",
       " '123477889a',\n",
       " 'aquhih220',\n",
       " 'ga98SIzk0NwhiZaE',\n",
       " 'lamborghin1',\n",
       " 'WUt9IZzE0OQ7PkNE',\n",
       " 'Iamthelegend1!',\n",
       " 'juliana19',\n",
       " 'jerusalem393',\n",
       " 'teemteem97',\n",
       " 'yu4cmn',\n",
       " 'elyass15@ajilent-ci',\n",
       " 'kino3434',\n",
       " 'jalal123456',\n",
       " '123maxbala',\n",
       " 'Iamthelegend1!',\n",
       " 'prisonbreak1',\n",
       " 'matiofox08',\n",
       " '746xitEGiqObog',\n",
       " '64959rodro',\n",
       " 'z3ro1sm',\n",
       " 'jerusalem393',\n",
       " '5gzj5uf',\n",
       " 'd04m11',\n",
       " 'hpqkoxsn5',\n",
       " '147963asd',\n",
       " '10Erjrlmebup0n',\n",
       " 'sanki1',\n",
       " 'gkrqjs6',\n",
       " 'bgrvl80',\n",
       " '147963asd',\n",
       " 'IjUcOtYqAwel725',\n",
       " 'cigicigi123',\n",
       " '612035180tok',\n",
       " 'znbl5tj1',\n",
       " '147963asd',\n",
       " 'yllime123',\n",
       " 'snolyuj04',\n",
       " 'gkrqjs6',\n",
       " 'hpqkoxsn5',\n",
       " '0870330135a',\n",
       " 'openup12',\n",
       " 'exitos2009',\n",
       " '12345yolanda',\n",
       " 'Iamthelegend1!',\n",
       " 'tamanagung6',\n",
       " 'Iamthelegend1!',\n",
       " 'moken7',\n",
       " '1972vishara',\n",
       " 'mmm23mm',\n",
       " 's9830950044',\n",
       " 'AVYq1lDE4MgAZfNt',\n",
       " 'a0972986650',\n",
       " 'xyws951753',\n",
       " 'ikanez886',\n",
       " '123477889a',\n",
       " 'alimagik1',\n",
       " 'megzy123',\n",
       " '147963asd',\n",
       " '5gzj5uf',\n",
       " 'asv5o9yu',\n",
       " 'as326159',\n",
       " 'potatobus150',\n",
       " '123maxbala',\n",
       " 'vehat387',\n",
       " 'intel1',\n",
       " 'finisterra1',\n",
       " 'meopvywk628',\n",
       " 'yqugu927',\n",
       " 'nello11',\n",
       " 'gozv3e5',\n",
       " 'bgrvl80',\n",
       " 'gandhi8513',\n",
       " 'gandhi8513',\n",
       " 'jalingo1',\n",
       " 'elyass15@ajilent-ci',\n",
       " 'omakiva153',\n",
       " 'potatobus150',\n",
       " 'znbl5tj1',\n",
       " 'okn9zp9o',\n",
       " 'wisal1234',\n",
       " 'v1118714',\n",
       " 'schalke04',\n",
       " '2010server',\n",
       " 'olmaz.',\n",
       " 'icap12',\n",
       " 'ldteugao6',\n",
       " 'damyvo114',\n",
       " 'farrukhcse12',\n",
       " 'sknq7m0',\n",
       " 'gkrqjs6',\n",
       " 'ekufite742',\n",
       " 'u6c8vhow',\n",
       " '159951josh',\n",
       " 'X9WVojjE4MgVAIiR',\n",
       " 'jonothepoop1',\n",
       " 's9830950044',\n",
       " 'tamanagung6',\n",
       " 'X9WVojjE4MgVAIiR',\n",
       " '7942vikas',\n",
       " '3vszncp4',\n",
       " 'mustang337',\n",
       " 'owote852',\n",
       " 'ldteugao6',\n",
       " '215466kenyi',\n",
       " 'qn5xpg3k00',\n",
       " 'b4NbTxDEyNgG141J',\n",
       " 'sasuke4',\n",
       " 'g3rappa',\n",
       " 'jytifok873',\n",
       " 'yk530mg8',\n",
       " 'RPFUOUDQwMwVW0AS',\n",
       " 'gaymaids1',\n",
       " 'klara-tershina3H',\n",
       " 'lamborghin1',\n",
       " 'uxyloga692',\n",
       " 'asgaliu11',\n",
       " 'rntprns7',\n",
       " 'openup12',\n",
       " 'wxS2ztDk4OATjBfI',\n",
       " 'yitbos77',\n",
       " 'planes123',\n",
       " 'kjkjkj1',\n",
       " '2fakjv',\n",
       " '2yz4ewwg',\n",
       " 'woon12',\n",
       " 'ass359',\n",
       " 'kyxvufl37',\n",
       " '2010server',\n",
       " 'meriton23',\n",
       " 'cigicigi123',\n",
       " 'yk530mg8',\n",
       " 'v10rica',\n",
       " 'yitbos77',\n",
       " '6tequila6',\n",
       " 'fk9qi21m',\n",
       " 'franczuk33',\n",
       " '12345yolanda',\n",
       " 'planes123',\n",
       " 'teemteem97',\n",
       " 'a2531106',\n",
       " 'uxyloga692',\n",
       " 'schalke04',\n",
       " 'gaymaids1',\n",
       " 'lzhzad1989',\n",
       " '123477889a',\n",
       " 'bugatti01',\n",
       " 'WUt9IZzE0OQ7PkNE',\n",
       " 'virush1n1',\n",
       " 'jalingo1',\n",
       " 't8IkFRDIxMAFV2JW',\n",
       " 'ginger972',\n",
       " 'g067057895',\n",
       " '2010server',\n",
       " 'yuri110995',\n",
       " 'rntprns7',\n",
       " 'polo2014',\n",
       " '7mV0pKTA3MgHy8Jv',\n",
       " 'mohantra1',\n",
       " 'sasuke4',\n",
       " 'nK0yKXTU0NQHZE2e',\n",
       " 'yut0838828185',\n",
       " '20010509wang',\n",
       " 'autan88',\n",
       " '929865yt',\n",
       " 'yitbos77',\n",
       " '123net123',\n",
       " 'k9b8cz6aj2',\n",
       " 'xiau5ff',\n",
       " 'witek1709',\n",
       " '2yz4ewwg',\n",
       " 'abizar08',\n",
       " 'oekojWyH120063',\n",
       " 'zgmfnwuq25',\n",
       " 'aquhih220',\n",
       " 'asv5o9yu',\n",
       " 'WUt9IZzE0OQ7PkNE',\n",
       " 'gkrqjs6',\n",
       " 'megzy123',\n",
       " 'wycinu436',\n",
       " 'a110804032',\n",
       " 'schalke04',\n",
       " '52558000aaa',\n",
       " 'enziitoo1234',\n",
       " 'patri1973',\n",
       " 'kP82iqDMxNgBMxBP',\n",
       " 'lamborghin1',\n",
       " '26522876p',\n",
       " '147963asd',\n",
       " 'jUV4dSDQwNwPpA36',\n",
       " '1234159hero',\n",
       " 's9830950044',\n",
       " 'djngeyut2707',\n",
       " '12345yolanda',\n",
       " 'jerusalem393',\n",
       " 'lzhzad1989',\n",
       " '0169395484a',\n",
       " 'kunyukbabi69',\n",
       " 'd4xQ3LjUwMQFVCYQ',\n",
       " 'lrhxmevb620',\n",
       " 'xanyrum650',\n",
       " 'mario489800',\n",
       " 'TyWM72UNEex8Q8Y',\n",
       " 'meriton23',\n",
       " 'kinga22',\n",
       " 'caramelo9',\n",
       " 'sofietou74',\n",
       " 'hqh2eYjQxOQPYIsA',\n",
       " 'hqh2eYjQxOQPYIsA',\n",
       " 'hasan18',\n",
       " '0870330135a',\n",
       " '2010server',\n",
       " 'gtlek',\n",
       " 'igejasy712',\n",
       " 'fnmsdha476',\n",
       " 'p2share',\n",
       " 'ebacuro434',\n",
       " 'p2share',\n",
       " 'hqh2eYjQxOQPYIsA',\n",
       " 'vuqADUSatAJO800',\n",
       " 'ass359',\n",
       " 'wycinu436',\n",
       " '147963asd',\n",
       " '1597535youssi',\n",
       " 'xp;ysmybst',\n",
       " 'igejasy712',\n",
       " 'kjkjkj1',\n",
       " 'znbl5tj1',\n",
       " 'rLLh4WDQ2OAWbDO5',\n",
       " 'ginger972',\n",
       " 'megzy123',\n",
       " 'sysoja794',\n",
       " 'matiz4533',\n",
       " 'kVczcljg4OA25Aeb',\n",
       " 'mayur@8netinfotech',\n",
       " 'kuntz80',\n",
       " 'sanjaime1',\n",
       " 'josue12',\n",
       " 'krishna2',\n",
       " 'nello11',\n",
       " '1qa2ws3ed4r',\n",
       " 'asgaliu11',\n",
       " 'rntprns7',\n",
       " 'asgaliu11',\n",
       " 'oekojWyH120063',\n",
       " 'rLLh4WDQ2OAWbDO5',\n",
       " 'kitty555',\n",
       " 'yqugu927',\n",
       " '33kanun03',\n",
       " 'barboza221294',\n",
       " '20Dgw7TQ0OQVdly7',\n",
       " 'terrassa6',\n",
       " 'Oshity07142014',\n",
       " '12345yolanda',\n",
       " 'JEQuloqOFUd102',\n",
       " 'kuntz80',\n",
       " 'nokia6020',\n",
       " 'b4NbTxDEyNgG141J',\n",
       " 'ryjypes139',\n",
       " 'ubojig109',\n",
       " 'jbtcnd6',\n",
       " 'mazdarx7',\n",
       " 'josue12',\n",
       " 'hpqkoxsn5',\n",
       " 'lymuvop730',\n",
       " 'franczuk33',\n",
       " 'vehat387',\n",
       " 'mike09',\n",
       " 'jEzZXUTE3MgJ4fVk',\n",
       " '2021848709.',\n",
       " 'asgaliu11',\n",
       " 'elyass15@ajilent-ci',\n",
       " 'qn5xpg3k00',\n",
       " '2yz4ewwg',\n",
       " 'pablo321159',\n",
       " '0VKWoODkwOAc0pZK',\n",
       " 'vuqADUSatAJO800',\n",
       " 'demon10',\n",
       " 'saule123',\n",
       " '07dpv1127b',\n",
       " 'x8512514',\n",
       " 'olmaz.',\n",
       " 'meriton23',\n",
       " 'zjl0kx03',\n",
       " 'bang6k',\n",
       " 'bencike7',\n",
       " 'frhnsvelhfr1',\n",
       " 'shotiko18',\n",
       " 'bgrvl80',\n",
       " '1ngaymuadong',\n",
       " 'tamanagung6',\n",
       " '1qa2ws3ed4rf',\n",
       " 'klara-tershina3H',\n",
       " '1597535youssi',\n",
       " 'IRZA98',\n",
       " 'autan88',\n",
       " 'elabadmin1386',\n",
       " 'kjkjkj1',\n",
       " 'killer5',\n",
       " 'as8594505',\n",
       " 'olmaz.',\n",
       " 'ebogel225',\n",
       " 'yuri110995',\n",
       " 'peluchin4',\n",
       " 'tin030201',\n",
       " '147963asd',\n",
       " 'teste10',\n",
       " 'openup12',\n",
       " 'pablo321159',\n",
       " 'cigicigi123',\n",
       " 'sanjaime1',\n",
       " 'Staterkom20081993',\n",
       " 'icap12',\n",
       " 'z3ro1sm',\n",
       " '2akira2',\n",
       " '283671gus',\n",
       " 'gvczfel801',\n",
       " 'we34dar88',\n",
       " 'teemteem97',\n",
       " 'bellsuki1',\n",
       " 'czuodhj972',\n",
       " 'cdann123',\n",
       " 'oscar2002',\n",
       " 'gutergut599',\n",
       " 'desmondkok21',\n",
       " '159951josh',\n",
       " 'josue12',\n",
       " 'xW8-3w7-MFB-CKH',\n",
       " 'autan88',\n",
       " 'g3rappa',\n",
       " 'yitbos77',\n",
       " 'uziwocy148',\n",
       " 'megzy123',\n",
       " 'ajyrew547',\n",
       " 'kino3434',\n",
       " 'ixehawojEPe418',\n",
       " 'just1n0k',\n",
       " 'prisonbreak1',\n",
       " 'lsdlsd1',\n",
       " 'Staterkom20081993',\n",
       " '1ngaymuadong',\n",
       " 'uou2dae',\n",
       " 'iwaguh884',\n",
       " 'afs34214',\n",
       " 'aslpls2009',\n",
       " '3vszncp4',\n",
       " 'abizar08',\n",
       " 'may112001',\n",
       " 'kenyu001',\n",
       " 'ldteugao6',\n",
       " 'meriton23',\n",
       " 'schalke04',\n",
       " 'jytifok873',\n",
       " 'elyass15@ajilent-ci',\n",
       " 'd6VyrkFV6oblxNs5N8cW',\n",
       " 'universe2908',\n",
       " 'gandhi8513',\n",
       " 'jEzZXUTE3MgJ4fVk',\n",
       " 'ryjypes139',\n",
       " 'k9b8cz6aj2',\n",
       " 's4m2dx9e6',\n",
       " 'schalke04',\n",
       " 'IjUcOtYqAwel725',\n",
       " 'ok>bdk',\n",
       " 'gdfn76',\n",
       " 'j2yj2yj2y',\n",
       " 'seng987321',\n",
       " 'kikeq102',\n",
       " 'nello11',\n",
       " 'pazzini24',\n",
       " 'rakag279',\n",
       " 'eVl19ADIxNAmU09N',\n",
       " 'omakiva153',\n",
       " 'novelia21',\n",
       " 'bencike7',\n",
       " 'xW8-3w7-MFB-CKH',\n",
       " 'DTUQG5jU5MwmR1L9',\n",
       " 'caramelo9',\n",
       " 'deryxi704',\n",
       " 'denise18',\n",
       " 'g3rappa',\n",
       " 'tucagu356',\n",
       " 'xp;ysmybst',\n",
       " 'taiga0088',\n",
       " 'pHyqueDIyNQ8vmhb',\n",
       " 'sanjaime1',\n",
       " 'atigi839',\n",
       " 'olmaz.',\n",
       " 'buqodym199',\n",
       " 'paulino123',\n",
       " 'kswa2mrv',\n",
       " '6yy6yy',\n",
       " 'control9',\n",
       " 'aslpls2009',\n",
       " 'asdasdf1',\n",
       " 'jalal123456',\n",
       " 'b4NbTxDEyNgG141J',\n",
       " 'lamborghin1',\n",
       " '215466kenyi',\n",
       " 'amoadios321',\n",
       " 'aquhih220',\n",
       " 'njmania114',\n",
       " '1qa2ws3ed4rf',\n",
       " 'may112001',\n",
       " '3CgRg8DA1NQY1iEj',\n",
       " 'oscar2002',\n",
       " 'kayal123',\n",
       " 'TyWM72UNEex8Q8Y',\n",
       " 'hosna1368',\n",
       " '3f5xd41l0ik7',\n",
       " 'spl51190595',\n",
       " 'khaled12',\n",
       " 'kayal123',\n",
       " 'hqh2eYjQxOQPYIsA',\n",
       " 'taiga0088',\n",
       " 'eth36498',\n",
       " 'farrukhcse12',\n",
       " 'ayles2266',\n",
       " 'pmcm110118008',\n",
       " 'lugerp08',\n",
       " 'jalal123456',\n",
       " 'RPFUOUDQwMwVW0AS',\n",
       " 'potatobus150',\n",
       " 'terrassa6',\n",
       " 'rqmswof2llb0',\n",
       " 'clyioqzgw42',\n",
       " 'RqsuUsDYxNgr8T40',\n",
       " 'gozv3e5',\n",
       " 'qn5xpg3k00',\n",
       " 'd04m11',\n",
       " '9950twofour0',\n",
       " 'kswa2mrv',\n",
       " 'wxS2ztDk4OATjBfI',\n",
       " 'sono11',\n",
       " 'fahad123',\n",
       " 'uoaef06gfqeb',\n",
       " 'tim80327',\n",
       " 'as326159',\n",
       " 'bugatti01',\n",
       " 'ekufite742',\n",
       " 'groster152',\n",
       " '20Dgw7TQ0OQVdly7',\n",
       " '2652033abc',\n",
       " 'sysoja794',\n",
       " 'legna13',\n",
       " 'pastorius88',\n",
       " '19821010a',\n",
       " 'ram@!sita15392',\n",
       " 'wearehis7',\n",
       " 'zcsntdmhe098',\n",
       " 'kswa2mrv',\n",
       " 'rqmswof2llb0',\n",
       " 'tim80327',\n",
       " 'uoaef06gfqeb',\n",
       " 'webhost08',\n",
       " 'mazdarx7',\n",
       " 'd6VyrkFV6oblxNs5N8cW',\n",
       " 'sono11',\n",
       " 'demon10',\n",
       " 'pass0port',\n",
       " 'junaid5',\n",
       " '26522876p',\n",
       " '600eretz',\n",
       " 'sbl571017',\n",
       " 'wo9aiwangyan',\n",
       " 'yhwbzci130',\n",
       " 'pablo321159',\n",
       " 'jcav26',\n",
       " 'lugerp08',\n",
       " 'nK0yKXTU0NQHZE2e',\n",
       " 'vuqADUSatAJO800',\n",
       " 'faranumar91',\n",
       " 'prisonbreak1',\n",
       " 'junaid5',\n",
       " 'desmondkok21',\n",
       " 'barboza221294',\n",
       " 'kenyu001',\n",
       " '123nicole',\n",
       " 'taccy12',\n",
       " 'autan88',\n",
       " '1qa2ws3ed4rf',\n",
       " 'patty94',\n",
       " 'teemteem97',\n",
       " 'meopvywk628',\n",
       " 'AVYq1lDE4MgAZfNt',\n",
       " 'hosna1368',\n",
       " 'pablo321159',\n",
       " 'beijing168',\n",
       " 'Zdyf0kjMzNQycqPx',\n",
       " 'Zdyf0kjMzNQycqPx',\n",
       " 'sergius1964',\n",
       " 'omakiva153',\n",
       " 'gopal8420',\n",
       " 'kswa2mrv',\n",
       " 'pugceya468',\n",
       " 'u6c8vhow',\n",
       " 'jbtcnd6',\n",
       " 'cigicigi123',\n",
       " 'lzhzad1989',\n",
       " 'DTUQG5jU5MwmR1L9',\n",
       " '6yy6yy',\n",
       " 'pxjwmeqyn5',\n",
       " 'satelite31',\n",
       " 'jalingo1',\n",
       " 'fbjurcd961',\n",
       " 'u6c8vhow',\n",
       " 'a03242241431a',\n",
       " 'sandra0547',\n",
       " 'zjl0kx03',\n",
       " 'mega0109',\n",
       " 'xlxlxl777',\n",
       " 'zjl0kx03',\n",
       " 'as8594505',\n",
       " 'gtlek',\n",
       " 'owote852',\n",
       " 'desmondkok21',\n",
       " '1justogax',\n",
       " '847XagYxUHUXOW',\n",
       " 'macias2010',\n",
       " '6975038lp',\n",
       " 'topgan22',\n",
       " 'sandra0547',\n",
       " 'paulino123',\n",
       " 'marita1',\n",
       " 'czuodhj972',\n",
       " 'kukimuki123',\n",
       " 'matha81',\n",
       " 'xW8-3w7-MFB-CKH',\n",
       " 'deryxi704',\n",
       " 'paulino123',\n",
       " 'deryxi704',\n",
       " 'b98nwtpriyesh',\n",
       " 'carla99',\n",
       " 'nicolas05',\n",
       " 'cesarmaio1',\n",
       " 'nhfdff2512',\n",
       " 'sd6x9s3s',\n",
       " 'metopelo1623',\n",
       " '8g8x2su3',\n",
       " 'killer5',\n",
       " 'j09000',\n",
       " 'vehat387',\n",
       " 'lugerp08',\n",
       " '123456ts',\n",
       " 'qopybuxi2',\n",
       " 'tin030201',\n",
       " 'fbjurcd961',\n",
       " 'fbjurcd961',\n",
       " 'ginger972',\n",
       " '0169395484a',\n",
       " 'julie1989',\n",
       " 'pilatyj280',\n",
       " 'yut0838828185',\n",
       " 'oatcake87',\n",
       " 'witek1709',\n",
       " 'ldteugao6',\n",
       " 'wuzsadav933',\n",
       " '727nimdadre',\n",
       " 'tukaxo486',\n",
       " '1234159hero',\n",
       " 'jerusalem393',\n",
       " 'zcsntdmhe098',\n",
       " 'PSVkampioen2013',\n",
       " 'lugerp08',\n",
       " '1katertje',\n",
       " 'natalia12',\n",
       " 'n501iomf',\n",
       " 'autan88',\n",
       " 'rogama69',\n",
       " 'bafiqkxwu0',\n",
       " 'clave2013',\n",
       " 'wuzyci421',\n",
       " 'yitbos77',\n",
       " 'zjl0kx03',\n",
       " 'den019520',\n",
       " 'exitos2009',\n",
       " '123477889a',\n",
       " 'pato221182',\n",
       " 'snolyuj04',\n",
       " 'damyvo114',\n",
       " 'alhama11408',\n",
       " 'asdasdf1',\n",
       " 'ns2b0727',\n",
       " '1ug2UKzQyMQBsleD',\n",
       " 'pass0port',\n",
       " 'jsm159167',\n",
       " 'patty94',\n",
       " 'juany57',\n",
       " 'yitbos77',\n",
       " 'aqyba894',\n",
       " 'hamqrc6',\n",
       " 'olmaz.',\n",
       " 'moimoimoi9',\n",
       " 'kyxvufl37',\n",
       " 'naseKoBUMIg295',\n",
       " 'kyxvufl37',\n",
       " 'polo2014',\n",
       " 'tspirits08',\n",
       " 'mohantra1',\n",
       " 'bghuyku37',\n",
       " 'faranumar91',\n",
       " 'kate13',\n",
       " 'kenneth610',\n",
       " 'DTUQG5jU5MwmR1L9',\n",
       " 'cUFUSYKIPuGo024',\n",
       " 'RPFUOUDQwMwVW0AS',\n",
       " 'asgaliu11',\n",
       " 'exitos2009',\n",
       " 'utuham322',\n",
       " 'we34dar88',\n",
       " 'limichan99',\n",
       " 'znbl5tj1',\n",
       " 'wbtdrieus345',\n",
       " 'e667794c1d',\n",
       " 'Herzberg@ABBOTT33656888commerce',\n",
       " 'tuto0378',\n",
       " '123456rajput',\n",
       " 'c3h8bkzr',\n",
       " 'barboza221294',\n",
       " 'bagdas2011',\n",
       " '4lgYVfzk1MwuzHcn',\n",
       " 'polo2014',\n",
       " 'josue12',\n",
       " 'rsuvxz08b',\n",
       " 'rqmswof2llb0',\n",
       " 'xanyrum650',\n",
       " 'rogyh820',\n",
       " 'anon13',\n",
       " 'pilatyj280',\n",
       " '9950twofour0',\n",
       " 'peluchin4',\n",
       " 'skoda06',\n",
       " 'oscar2002',\n",
       " 'zcsntdmhe098',\n",
       " 'warriors08',\n",
       " 'desmondkok21',\n",
       " 'barboza221294',\n",
       " 'xve33ea',\n",
       " '0870330135a',\n",
       " 'ass359',\n",
       " 'd6VyrkFV6oblxNs5N8cW',\n",
       " 'den019520',\n",
       " 'GGmm26120904..',\n",
       " 'parvizrus13',\n",
       " 'ppnyadam09',\n",
       " '6tequila6',\n",
       " 'acetita478',\n",
       " 'o7ShLdTM0NAQRI7E',\n",
       " 'jesmond26',\n",
       " 'DTUQG5jU5MwmR1L9',\n",
       " 'mialr325',\n",
       " 'colorado27',\n",
       " 'uou2dae',\n",
       " 'clyioqzgw42',\n",
       " 'kah4544875',\n",
       " 'puegwajy416',\n",
       " 'yuri110995',\n",
       " 'a03242241431a',\n",
       " 'bambink182',\n",
       " 'v1118714',\n",
       " 'snolyuj04',\n",
       " 'woogee04',\n",
       " 'tin030201',\n",
       " 'elperro1',\n",
       " 'as326159',\n",
       " 'kyodai666',\n",
       " 'hot622204',\n",
       " 'pazzini24',\n",
       " 'gracimir87',\n",
       " '8g8x2su3',\n",
       " '000webhostcom',\n",
       " 'eth36498',\n",
       " 'rntprns7',\n",
       " '2akira2',\n",
       " 'gozv3e5',\n",
       " '147963asd',\n",
       " 'colorado27',\n",
       " 'sbnivetha123',\n",
       " 'pikey231',\n",
       " 'kino3434',\n",
       " 'yitbos77',\n",
       " 'papasito1991',\n",
       " 'raykuaz32',\n",
       " 'patata91',\n",
       " 'ym2130104',\n",
       " 'saule123',\n",
       " 'q0pv0fk',\n",
       " 'shH3t7TcyOQwKRLt',\n",
       " 'osimeytju12',\n",
       " 'tiga33',\n",
       " 'cdann123',\n",
       " '0lELoCDI1NAy8u7D',\n",
       " 'sebax2013',\n",
       " 'labarge1',\n",
       " 'uqilyni846',\n",
       " '1A2Z3E4R',\n",
       " '1k9izx',\n",
       " 'n501iomf',\n",
       " 'hosna1368',\n",
       " '4165000yakub',\n",
       " 'papasito1991',\n",
       " 'ejeko677',\n",
       " 'shH3t7TcyOQwKRLt',\n",
       " 'jj46azbo',\n",
       " 'jr88072635',\n",
       " 'ilonu497',\n",
       " 'xp;ysmybst',\n",
       " 'itengf12',\n",
       " 'aziz098765',\n",
       " 'kaiden12',\n",
       " 'jalingo1',\n",
       " 'gandhi8513',\n",
       " 'holamundo1',\n",
       " 'a0972986650',\n",
       " 'damyvo114',\n",
       " 'daylit9',\n",
       " 'idofo673',\n",
       " 'ypodahe201',\n",
       " 'tim80327',\n",
       " 'may112001',\n",
       " 'LypOJUfuLYrO477',\n",
       " '19821010a',\n",
       " 'sw10d014',\n",
       " 'luthien123',\n",
       " 'roxana1993',\n",
       " 'mndzbqkv651',\n",
       " 'webhostv1t1n',\n",
       " 'wisal1234',\n",
       " '6tequila6',\n",
       " 's9830950044',\n",
       " 'rakag279',\n",
       " 'omakiva153',\n",
       " 'fudijep286',\n",
       " 'gutergut599',\n",
       " 'alodise603',\n",
       " 'bafiqkxwu0',\n",
       " '000martin',\n",
       " 'ym2130104',\n",
       " 'samemene@sm',\n",
       " 'aa123000',\n",
       " 'may112001',\n",
       " 'kyxvufl37',\n",
       " 'linhna288',\n",
       " 'alhama11408',\n",
       " 'den019520',\n",
       " 'afan520307',\n",
       " 'ypodahe201',\n",
       " 'ypodahe201',\n",
       " 'universe2908',\n",
       " 'zedika521',\n",
       " 'Oshity07142014',\n",
       " 'aa123000',\n",
       " 'teemteem97',\n",
       " 'PSVkampioen2013',\n",
       " 'openup12',\n",
       " 'farrukhcse12',\n",
       " '210496av',\n",
       " 'w1ll1ams',\n",
       " 'jEzZXUTE3MgJ4fVk',\n",
       " 'markama10',\n",
       " 'kenneth610',\n",
       " 'yqugu927',\n",
       " 'cdann123',\n",
       " 'www32223222',\n",
       " 'daaxvie1',\n",
       " 'stalucia66',\n",
       " 'jntjmh7',\n",
       " '69556236gu',\n",
       " 'snolyuj04',\n",
       " '4XakB8TkzOQWCS7Y',\n",
       " 'gerardway1',\n",
       " 'mtvwyz001',\n",
       " '01161590m',\n",
       " 'up8444',\n",
       " 'zb08110229',\n",
       " 'nebunule2',\n",
       " '1597535youssi',\n",
       " 'hodygid757',\n",
       " 'jUV4dSDQwNwPpA36',\n",
       " 'mario489800',\n",
       " 'gjm666',\n",
       " 'novelia21',\n",
       " 'ryjypes139',\n",
       " 'kino3434',\n",
       " 'deryxi704',\n",
       " 'buqodym199',\n",
       " 'hodygid757',\n",
       " 'puegwajy416',\n",
       " 'cxZLmFDYwNA1lUK9',\n",
       " 'caramelo9',\n",
       " 'oslicek00',\n",
       " 'JEQuloqOFUd102',\n",
       " 'xiau5ff',\n",
       " '030005qw',\n",
       " 'webhostv1t1n',\n",
       " 'rsuvxz08b',\n",
       " 'wasanun13',\n",
       " 'autan88',\n",
       " 'savas123x',\n",
       " 'komorek11',\n",
       " 'calung2007',\n",
       " 'joy112495',\n",
       " '2021848709.',\n",
       " 'akucinta12',\n",
       " 'samael666',\n",
       " 'willboss13',\n",
       " 'islamasma12',\n",
       " 'mustang337',\n",
       " 'yu86640132',\n",
       " 'trabajonet9',\n",
       " 'angelinajol52',\n",
       " '9950twofour0',\n",
       " 'byeypb2',\n",
       " 'emilly123',\n",
       " 'menti12061995',\n",
       " 'zb08110229',\n",
       " 'orzwnyj91',\n",
       " 'kry1z9',\n",
       " 'up8444',\n",
       " 'paladinas1',\n",
       " '000webhostcom',\n",
       " 'kahcyxvj24',\n",
       " 'ykfums1',\n",
       " 'calcifer32',\n",
       " 'adminmao888',\n",
       " 'saule123',\n",
       " '07dpv1127b',\n",
       " 'midgeman8505',\n",
       " 'woaini0',\n",
       " 'housefly74',\n",
       " 'polo2014',\n",
       " '000webhostcom',\n",
       " 'krumbul123',\n",
       " 'kayal123',\n",
       " 'j03l4ytr1',\n",
       " 'anon13',\n",
       " 'qopybuxi2',\n",
       " 'seng987321',\n",
       " 'sandra0547',\n",
       " 'desmondkok21',\n",
       " '215466kenyi',\n",
       " 'frenchtoast42',\n",
       " 'h3ndr4',\n",
       " 'il0vey0u',\n",
       " 'lqksuym982',\n",
       " 'ts02521712',\n",
       " '27121995qw',\n",
       " 'kb6188',\n",
       " 'zuryvu986',\n",
       " 'synyxyr723',\n",
       " '101010hadis',\n",
       " 'vietnga92',\n",
       " 'bijou2012',\n",
       " '1907sedat58',\n",
       " 'obstacle25',\n",
       " 'emilly123',\n",
       " 'espinosa81',\n",
       " 'g3rappa',\n",
       " 'RqsuUsDYxNgr8T40',\n",
       " 'lizndina1',\n",
       " 'cristiano7',\n",
       " '123charger',\n",
       " 'IjUcOtYqAwel725',\n",
       " ...]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x # printing x list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " ...]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y # printing y list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOW WE NEED TO APPLY TF-IDF(TERM FREQUENCY - INVERSE DOCUMENT FREQUENCY) OF DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a custom function to split the word into characters\n",
    "def word_divide_char(inputs):\n",
    "    character=[]\n",
    "    for i in inputs:\n",
    "        character.append(i)\n",
    "    return character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['k', 'z', 'd', 'e', '5', '5', '7', '7']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_divide_char('kzde5577')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we import TF-IDF vectorizer to convert String data into numerical data\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer=TfidfVectorizer(tokenizer=word_divide_char) # we tokenize the data on the basis of word_divide_char functon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply TF-IDF vectorizer on data, x(all passwords)\n",
    "X=vectorizer.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(669639, 131)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape # second column size increased because it is now vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\x02',\n",
       " '\\x04',\n",
       " '\\x05',\n",
       " '\\x08',\n",
       " '\\x0e',\n",
       " '\\x0f',\n",
       " '\\x10',\n",
       " '\\x12',\n",
       " '\\x16',\n",
       " '\\x17',\n",
       " '\\x19',\n",
       " '\\x1b',\n",
       " '\\x1c',\n",
       " '\\x1e',\n",
       " ' ',\n",
       " '!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~',\n",
       " '\\x7f',\n",
       " '\\x81',\n",
       " '\\x8d',\n",
       " '\\xa0',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names() # getting all the features of our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x131 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 6 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_document_vector=X[0]\n",
    "first_document_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.56750685],\n",
       "        [0.        ],\n",
       "        [0.59109996],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.28602101],\n",
       "        [0.22136972],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.29165032],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.33565508],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_document_vector.T.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TF-IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.591100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.567507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z</th>\n",
       "      <td>0.335655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k</th>\n",
       "      <td>0.291650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>0.286021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>;</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      TF-IDF\n",
       "7   0.591100\n",
       "5   0.567507\n",
       "z   0.335655\n",
       "k   0.291650\n",
       "d   0.286021\n",
       "..       ...\n",
       "<   0.000000\n",
       ";   0.000000\n",
       "9   0.000000\n",
       "8   0.000000\n",
       "   0.000000\n",
       "\n",
       "[131 rows x 1 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we need to prepare the data for modelling purpose with first column as feature, and second column as the importance of that feature\n",
    "# this is final data for modelling purpose\n",
    "df=pd.DataFrame(first_document_vector.T.todense(),index=vectorizer.get_feature_names(),columns=['TF-IDF'])\n",
    "df.sort_values(by=['TF-IDF'],ascending=False) # arranged the data in decreaing order of TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we need to pass this data for modelling purpose (Applying Machine Learning)\n",
    "# first we need to split the data for training and testing purpose\n",
    "# train - To learn the relationship within data, \n",
    "# test - To do predictions, and this testing data will be unseen to my model\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.2) # using train_test_split, we splitted the data, train - 80% of data, test - 20% of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(535711, 131)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now after splitting our data is ready for modelling stuff\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=LogisticRegression(random_state=0,multi_class='multinomial') # we consider case of multinomial logistic regression, because we have three types of password - 0,1,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='multinomial', random_state=0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train,y_train) # fitting our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we have trained our data, so we consider some rare case which is not in data, and predicts its strength\n",
    "dt=np.array(['%@123abcd'])\n",
    "pred=vectorizer.transform(dt)\n",
    "clf.predict(pred) # returned 1 there fore password is of average strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same way we can do prediction on X test data, In the same we can also consider some of the advanced classifier, such as adabboost, catboost, randomforest\n",
    "y_pred=clf.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHECKING ACCURACY OF  MODEL USING CONFUSION_MATRIX, ACCURACY_SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5425 12682    13]\n",
      " [ 3891 92580  2548]\n",
      " [   22  5106 11661]]\n",
      "0.8188429603966311\n"
     ]
    }
   ],
   "source": [
    "cm=confusion_matrix(y_test,y_pred)\n",
    "print(cm)\n",
    "print(accuracy_score(y_test,y_pred)) # here 5425, 92580, 11661 are true prediction , rest are not true predictions, therefore accuracy is good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.30      0.40     18120\n",
      "           1       0.84      0.93      0.88     99019\n",
      "           2       0.82      0.69      0.75     16789\n",
      "\n",
      "    accuracy                           0.82    133928\n",
      "   macro avg       0.75      0.64      0.68    133928\n",
      "weighted avg       0.80      0.82      0.80    133928\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# creatiing classification model report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
